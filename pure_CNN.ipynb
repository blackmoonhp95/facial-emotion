{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silver-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "departmental-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_training = pd.read_csv('metadata_processed.csv')\n",
    "source_validation = pd.read_csv('icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inappropriate-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "indexes = [x for x in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smart-buying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [WinError 183] Cannot create a file when that file already exists: 'Dataset/Training/Angry'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  for name in emotions:\n",
    "    os.mkdir('Dataset/Training/'+name)\n",
    "except FileExistsError as e:\n",
    "  print('Error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informative-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [WinError 183] Cannot create a file when that file already exists: 'Dataset/Validation/Angry'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  for name in emotions:\n",
    "    os.mkdir('Dataset/Validation/'+name)\n",
    "except FileExistsError as e:\n",
    "  print('Error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recognized-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angry was filled up with images!\n",
      "Disgust was filled up with images!\n",
      "Fear was filled up with images!\n",
      "Happy was filled up with images!\n",
      "Sad was filled up with images!\n",
      "Surprise was filled up with images!\n",
      "Neutral was filled up with images!\n"
     ]
    }
   ],
   "source": [
    "for name in emotions:\n",
    "  if len(os.listdir('Dataset/Training/{}'.format(name))) == 0:\n",
    "    new_source = source_training[source_training['emotion'] == name]\n",
    "    for i in range(new_source.shape[0]):\n",
    "      img = new_source.iloc[i, 1]\n",
    "      img = [x for x in img.split(' ')]\n",
    "      img = np.array(img, dtype='float32')\n",
    "      img = img.reshape(48,-1)\n",
    "      cv2.imwrite('Dataset/Training/{}/{}.jpg'.format(name, i), img)\n",
    "  else:\n",
    "    print('{} was filled up with images!'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "olympic-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angry was filled up with images!\n",
      "Disgust was filled up with images!\n",
      "Fear was filled up with images!\n",
      "Happy was filled up with images!\n",
      "Sad was filled up with images!\n",
      "Surprise was filled up with images!\n",
      "Neutral was filled up with images!\n"
     ]
    }
   ],
   "source": [
    "for index, name in zip(indexes, emotions):\n",
    "  if len(os.listdir('Dataset/Validation/{}'.format(name))) == 0:\n",
    "    new_source = source_validation[source_validation['emotion'] == index]\n",
    "    for i in range(500):\n",
    "      img = new_source.iloc[i, 2]\n",
    "      img = [x for x in img.split(' ')]\n",
    "      img = np.array(img, dtype='float32')\n",
    "      img = img.reshape(48,-1)\n",
    "      cv2.imwrite('Dataset/Validation/{}/{}.jpg'.format(name, i), img)\n",
    "  else:\n",
    "    print('{} was filled up with images!'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "classified-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Angry 5126\n",
      "Training Disgust 5126\n",
      "Training Fear 5126\n",
      "Training Happy 5126\n",
      "Training Sad 5126\n",
      "Training Surprise 5126\n",
      "Training Neutral 5126\n",
      "Validation Angry 500\n",
      "Validation Disgust 500\n",
      "Validation Fear 500\n",
      "Validation Happy 500\n",
      "Validation Sad 500\n",
      "Validation Surprise 500\n",
      "Validation Neutral 500\n"
     ]
    }
   ],
   "source": [
    "for name in emotions:\n",
    "  print(\"Training\", name, len(os.listdir(f'Dataset/Training/{name}')))\n",
    "for name in emotions:\n",
    "  print(\"Validation\", name, len(os.listdir(f'Dataset/Validation/{name}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elder-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35882 images belonging to 7 classes.\n",
      "Found 3500 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_train = ImageDataGenerator(rescale=1/255,\n",
    "                               rotation_range=40, \n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True, \n",
    "                               fill_mode='nearest')\n",
    "\n",
    "gen_valid = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "img_train = gen_train.flow_from_directory('Dataset/Training/', target_size=(48, 48), batch_size=32, \n",
    "                                          class_mode='categorical', color_mode='grayscale')\n",
    "img_valid = gen_valid.flow_from_directory('Dataset/validation/', target_size=(48, 48), batch_size=32, \n",
    "                                          class_mode='categorical', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "similar-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "256/256 [==============================] - 51s 198ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 58s 228ms/step - loss: 1.9461 - accuracy: 0.1461 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 53s 208ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9461 - val_accuracy: 0.1429\n",
      "Epoch 4/20\n",
      " 58/256 [=====>........................] - ETA: 33s - loss: 1.9463 - accuracy: 0.1401"
     ]
    }
   ],
   "source": [
    "history = model.fit(img_train, epochs=20, steps_per_epoch=256, validation_data=img_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "his = pd.DataFrame(history.history)\n",
    "his.to_csv('bs64-e50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-howard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
